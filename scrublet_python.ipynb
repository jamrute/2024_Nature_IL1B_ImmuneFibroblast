{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scrublet as scr\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import anndata\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"./final_global_annotated.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bh(pvalues):\n",
    "    '''\n",
    "    Computes the Benjamini-Hochberg FDR correction.\n",
    "\n",
    "    Input:\n",
    "        * pvals - vector of p-values to correct\n",
    "    '''\n",
    "    n = int(pvalues.shape[0])\n",
    "    new_pvalues = np.empty(n)\n",
    "    values = [ (pvalue, i) for i, pvalue in enumerate(pvalues) ]\n",
    "    values.sort()\n",
    "    values.reverse()\n",
    "    new_values = []\n",
    "    for i, vals in enumerate(values):\n",
    "        rank = n - i\n",
    "        pvalue, index = vals\n",
    "        new_values.append((n/rank) * pvalue)\n",
    "    for i in range(0, int(n)-1):\n",
    "        if new_values[i] < new_values[i+1]:\n",
    "            new_values[i+1] = new_values[i]\n",
    "    for i, vals in enumerate(values):\n",
    "        pvalue, index = vals\n",
    "        new_pvalues[index] = new_values[i]\n",
    "    return new_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change directory \n",
    "    \n",
    "CWD = \"/Users/jamrute/Desktop/\"\n",
    "\n",
    "from os import chdir\n",
    "chdir(CWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 144027 × 270\n",
       "    obs: 'sample', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'propmt', 'rna_size', 'ngene', 'prot_size', 'bc', 'droplet_class', 'nCount_ADT', 'nFeature_ADT', 'nCount_CITE', 'nFeature_CITE', 'nCount_SCT', 'nFeature_SCT', 'SCT.weight', 'CITE.weight', 'sct.dsb_snn_res.0.1', 'sct.dsb_snn_res.0.2', 'sct.dsb_snn_res.0.3', 'sct.dsb_snn_res.0.4', 'sct.dsb_snn_res.0.5', 'sct.dsb_snn_res.0.6', 'sct.dsb_snn_res.0.7', 'sct.dsb_snn_res.0.8', 'seurat_clusters', 'Sample.name', 'Date.of.harvest', 'HF.etiology', 'Txp.LVAD', 'Race', 'Sex', 'Age', 'time.since.last.ischemic.event', 'BMI', 'HTN', 'DM', 'MI', 'Stent', 'CABG', 'CKD', 'Smoker', 'EF', 'CO', 'Intermacs..profile.1....profile.2...2..profile.3.3..profile.4.4..profile.5.5.', 'Atrial.arrh', 'Ventricular.arrh', 'MR', 'MS', 'AR', 'AS', 'Pacemaker', 'ICD', 'Temp.mech.support..pre.op.', 'Durable.mech.support..pre.op', 'GDMT', 'Inotropes', 'annotation.0.1', 'HF.etiology2'\n",
       "    var: 'features'\n",
       "    obsm: 'X_adt.umap', 'X_pdsb', 'X_rna.umap', 'X_sct.dsb_wnn_umap'\n",
       "    varm: 'PDSB'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_components=30 must be between 1 and min(n_samples, n_features)=15 with svd_solver='arpack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e7db2eca8b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#set up and run Scrublet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mscrub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScrublet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdoublet_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_doublets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrub_doublets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mscrub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0madata_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scrublet_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoublet_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scrublet/scrublet.py\u001b[0m in \u001b[0;36mscrub_doublets\u001b[0;34m(self, synthetic_doublet_umi_subsampling, use_approx_neighbors, distance_metric, get_doublet_neighbor_parents, min_counts, min_cells, min_gene_variability_pctl, log_transform, mean_center, normalize_variance, n_prin_comps, svd_solver, verbose)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean_center\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mprint_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Embedding transcriptomes using PCA...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mpipeline_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_prin_comps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_prin_comps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_solver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mprint_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Embedding transcriptomes using Truncated SVD...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scrublet/helper_functions.py\u001b[0m in \u001b[0;36mpipeline_pca\u001b[0;34m(self, n_prin_comps, random_state, svd_solver)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mX_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_E_sim_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_prin_comps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_solver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_manifold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    509\u001b[0m                              \u001b[0;34m\"svd_solver='%s'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                              % (n_components, min(n_samples, n_features),\n\u001b[0;32m--> 511\u001b[0;31m                                 svd_solver))\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             raise ValueError(\"n_components=%r must be of type int \"\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=30 must be between 1 and min(n_samples, n_features)=15 with svd_solver='arpack'"
     ]
    }
   ],
   "source": [
    "####### main\n",
    "meta = adata.obs\n",
    "sc.settings.verbosity = 1  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "\n",
    "scorenames = ['scrublet_score','scrublet_cluster_score','bh_pval']\n",
    "os.makedirs('scrublet-scores')\n",
    "\n",
    "###\n",
    "\n",
    "for sample in meta['sample'].unique():\n",
    "    print(sample)\n",
    "    #import data\n",
    "    adata_sample = adata[adata.obs['sample'] == sample]\n",
    "    \n",
    "    #set up and run Scrublet\n",
    "    scrub = scr.Scrublet(adata_sample.X)\n",
    "    doublet_scores, predicted_doublets = scrub.scrub_doublets(verbose=False)\n",
    "    scrub.plot_histogram();\n",
    "    adata_sample.obs['scrublet_score'] = doublet_scores\n",
    "    #overcluster prep. run turbo basic scanpy pipeline\n",
    "    sc.pp.filter_genes(adata_sample, min_cells=3)\n",
    "    sc.pp.normalize_per_cell(adata_sample, counts_per_cell_after=1e4)\n",
    "    sc.pp.log1p(adata_sample)\n",
    "    sc.pp.highly_variable_genes(adata_sample, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "    adata_sample = adata_sample[:, adata_sample.var['highly_variable']]\n",
    "    sc.pp.scale(adata_sample, max_value=10)\n",
    "    sc.tl.pca(adata_sample, svd_solver='arpack')\n",
    "    sc.pp.neighbors(adata_sample)\n",
    "    #eoverclustering proper - do basic clustering first, then cluster each cluster\n",
    "    sc.tl.louvain(adata_sample)\n",
    "    for clus in np.unique(adata_sample.obs['louvain']):\n",
    "        sc.tl.louvain(adata_sample, restrict_to=('louvain',[clus]))\n",
    "        adata_sample.obs['louvain'] = adata_sample.obs['louvain_R']\n",
    "    #compute the cluster scores - the median of Scrublet scores per overclustered cluster\n",
    "    for clus in np.unique(adata_sample.obs['louvain']):\n",
    "        adata_sample.obs.loc[adata_sample.obs['louvain']==clus, 'scrublet_cluster_score'] = \\\n",
    "            np.median(adata_sample.obs.loc[adata_sample.obs['louvain']==clus, 'scrublet_score'])\n",
    "    #now compute doublet p-values. figure out the median and mad (from above-median values) for the distribution\n",
    "    med = np.median(adata_sample.obs['scrublet_cluster_score'])\n",
    "    mask = adata_sample.obs['scrublet_cluster_score']>med\n",
    "    mad = np.median(adata_sample.obs['scrublet_cluster_score'][mask]-med)\n",
    "    #let's do a one-sided test. the Bertie write-up does not address this but it makes sense\n",
    "    pvals = 1-scipy.stats.norm.cdf(adata_sample.obs['scrublet_cluster_score'], loc=med, scale=1.4826*mad)\n",
    "    adata_sample.obs['bh_pval'] = bh(pvals)\n",
    "    #create results data frame for single sample and copy stuff over from the adata object\n",
    "    scrublet_sample = pd.DataFrame(0, index=adata_sample.obs_names, columns=scorenames)\n",
    "    for meta in scorenames:\n",
    "        scrublet_sample[meta] = adata_sample.obs[meta]\n",
    "    #write out complete sample scores\n",
    "    scrublet_sample.to_csv('scrublet-scores/'+sample+'.csv')\n",
    "    scrub.plot_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrub1 = pd.read_csv(\"./scrublet-scores/1.csv\", index_col=0)\n",
    "scrub2 = pd.read_csv(\"./scrublet-scores/2.csv\", index_col=0)\n",
    "scrub3 = pd.read_csv(\"./scrublet-scores/3.csv\", index_col=0)\n",
    "scrub4 = pd.read_csv(\"./scrublet-scores/4.csv\", index_col=0)\n",
    "scrub5 = pd.read_csv(\"./scrublet-scores/5.csv\", index_col=0)\n",
    "scrub6 = pd.read_csv(\"./scrublet-scores/6.csv\", index_col=0)\n",
    "scrub7 = pd.read_csv(\"./scrublet-scores/7.csv\", index_col=0)\n",
    "scrub8 = pd.read_csv(\"./scrublet-scores/8.csv\", index_col=0)\n",
    "scrub9 = pd.read_csv(\"./scrublet-scores/9.csv\", index_col=0)\n",
    "scrub10 = pd.read_csv(\"./scrublet-scores/10.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [scrub1, scrub2, scrub3, scrub4, scrub5, scrub6, scrub7, scrub8, scrub9, scrub10]\n",
    "scrub_all = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrub_all.to_csv('scrublet-scores/all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
